{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.8/site-packages (1.0.3)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.8/site-packages (1.18.3)\n",
      "Requirement already satisfied: gql in ./.venv/lib/python3.8/site-packages (0.4.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in ./.venv/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in ./.venv/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.10.0 in ./.venv/lib/python3.8/site-packages (from gql) (1.14.0)\n",
      "Requirement already satisfied: graphql-core<3,>=2 in ./.venv/lib/python3.8/site-packages (from gql) (2.3.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in ./.venv/lib/python3.8/site-packages (from gql) (2.3)\n",
      "Requirement already satisfied: requests<3,>=2.12 in ./.venv/lib/python3.8/site-packages (from gql) (2.23.0)\n",
      "Requirement already satisfied: rx<2,>=1.6 in ./.venv/lib/python3.8/site-packages (from graphql-core<3,>=2->gql) (1.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.8/site-packages (from requests<3,>=2.12->gql) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./.venv/lib/python3.8/site-packages (from requests<3,>=2.12->gql) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./.venv/lib/python3.8/site-packages (from requests<3,>=2.12->gql) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in ./.venv/lib/python3.8/site-packages (from requests<3,>=2.12->gql) (3.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "pip install pandas numpy gql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gql import gql, Client\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPHQL_ENDPOINT = \"http://localhost:8080/v1/graphql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "transport = RequestsHTTPTransport(\n",
    "    url=GRAPHQL_ENDPOINT,\n",
    "    use_json=True,\n",
    "    headers={\"Content-type\": \"application/json\"},\n",
    "    verify=False)\n",
    "\n",
    "client = Client(\n",
    "    retries=3,\n",
    "    transport=transport,\n",
    "    fetch_schema_from_transport=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query the database\n",
    "\n",
    "Let's get some data. The following code queries the GraphQL endpoint and gets the 2-level citation graph for a specific paper. That is, it gets all papers that are at most 2 hops away. Assuming that each paper on average cites 30 other papers, the result would be 1 + 30 * 30 = ~900 records. Note that the database currently only contains papers labeled as \"Computer Science\", so cited papers from other fields will not show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper title is matched via sql LIKE, so this can be a substring of the title\n",
    "PAPER_TITLE = \"%Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = gql(\"\"\"\n",
    "fragment paper_fields on papers {\n",
    "  id\n",
    "  title\n",
    "  year\n",
    "  num_citations\n",
    "}\n",
    "\n",
    "query papers($title: String!) {\n",
    "  papers(limit: 1, where: {title: {_like: $title}}, offset: 0) {\n",
    "    ...paper_fields\n",
    "    cites(args: {limit_: 100}) {\n",
    "      ...paper_fields\n",
    "      cites(args: {limit_: 100}) {\n",
    "        ...paper_fields\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = client.execute(query, variable_values={\"title\": PAPER_TITLE})\n",
    "root = papers[\"papers\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_recursively(paper, fn):\n",
    "    \"\"\"Helper function to process the recursive graph data structure. It runs a function for each element in the graph\"\"\"\n",
    "    fn(paper)\n",
    "    if not \"cites\" in paper:\n",
    "        return\n",
    "    for cited_paper in paper[\"cites\"]:\n",
    "        process_recursively(cited_paper, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataFrame\n",
    "\n",
    "Next, let's create a dataframe of all papers in the graph. Here, duplicates are eliminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837 unique papers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>num_citations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c39fb7a46335c23f7529dd6f9f980462fd38653a</th>\n",
       "      <td>Mastering Atari, Go, Chess and Shogi by Planni...</td>\n",
       "      <td>2019</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0ab3f7ecbdc5a33565a234215604a6ca9d155a33</th>\n",
       "      <td>Rainbow: Combining Improvements in Deep Reinfo...</td>\n",
       "      <td>2018</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>049c6e5736313374c6e594c34b9be89a3a09dced</th>\n",
       "      <td>FeUdal Networks for Hierarchical Reinforcement...</td>\n",
       "      <td>2017</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10a4992ece5baea79326a8878a6244eeacbc6af5</th>\n",
       "      <td>Deep Successor Reinforcement Learning</td>\n",
       "      <td>2016</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2319a491378867c7049b3da055c5df60e1671158</th>\n",
       "      <td>Playing Atari with Deep Reinforcement Learning</td>\n",
       "      <td>2013</td>\n",
       "      <td>2793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      title  \\\n",
       "id                                                                                            \n",
       "c39fb7a46335c23f7529dd6f9f980462fd38653a  Mastering Atari, Go, Chess and Shogi by Planni...   \n",
       "0ab3f7ecbdc5a33565a234215604a6ca9d155a33  Rainbow: Combining Improvements in Deep Reinfo...   \n",
       "049c6e5736313374c6e594c34b9be89a3a09dced  FeUdal Networks for Hierarchical Reinforcement...   \n",
       "10a4992ece5baea79326a8878a6244eeacbc6af5              Deep Successor Reinforcement Learning   \n",
       "2319a491378867c7049b3da055c5df60e1671158     Playing Atari with Deep Reinforcement Learning   \n",
       "\n",
       "                                          year  num_citations  \n",
       "id                                                             \n",
       "c39fb7a46335c23f7529dd6f9f980462fd38653a  2019             25  \n",
       "0ab3f7ecbdc5a33565a234215604a6ca9d155a33  2018            397  \n",
       "049c6e5736313374c6e594c34b9be89a3a09dced  2017            269  \n",
       "10a4992ece5baea79326a8878a6244eeacbc6af5  2016             77  \n",
       "2319a491378867c7049b3da055c5df60e1671158  2013           2793  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame of all papers that appear in this subgraph\n",
    "paper_map = {}\n",
    "def add_paper(paper):\n",
    "    fields = { k : paper[k] for k in paper if k != \"cites\" }\n",
    "    paper_map[paper[\"id\"]] = fields\n",
    "process_recursively(root, add_paper)\n",
    "papers_df = pd.DataFrame.from_records(list(paper_map.values()), index=\"id\")\n",
    "\n",
    "print(f\"{len(papers_df)} unique papers\")\n",
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Popular Papers\n",
    "\n",
    "The following shows papers with the overall most citations present in this subgraph. These are the popular papers that are somewhat relevant to the root paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>num_citations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abd1c342495432171beb7ca8fd9551ef13cbd0ff</th>\n",
       "      <td>ImageNet Classification with Deep Convolutiona...</td>\n",
       "      <td>2012</td>\n",
       "      <td>40246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a6cb366736791bcccc5c8639de5a8f9636bf87e8</th>\n",
       "      <td>Adam: A Method for Stochastic Optimization</td>\n",
       "      <td>2015</td>\n",
       "      <td>33621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2c03df8b48bf3fa39054345bafabfeff15bfd11d</th>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>2016</td>\n",
       "      <td>32655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eb42cf88027de515750f230b23b1a057dc782108</th>\n",
       "      <td>Very Deep Convolutional Networks for Large-Sca...</td>\n",
       "      <td>2014</td>\n",
       "      <td>27495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13d4c2f76a7c1a4d0a71204e1d5d263a3f5a7986</th>\n",
       "      <td>Random Forests</td>\n",
       "      <td>2004</td>\n",
       "      <td>24563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44d2abe2175df8153f465f6c39b68b76a0d40ab9</th>\n",
       "      <td>Long Short-Term Memory</td>\n",
       "      <td>1997</td>\n",
       "      <td>20985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97efafdb4a3942ab3efba53ded7413199f79c054</th>\n",
       "      <td>Reinforcement Learning: An Introduction</td>\n",
       "      <td>2005</td>\n",
       "      <td>18170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4f607f03272e4d62708f5b2441355f9e005cb452</th>\n",
       "      <td>Convex Optimization</td>\n",
       "      <td>2006</td>\n",
       "      <td>16074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2e62d1345b340d5fda3b092c460264b9543bc4b5</th>\n",
       "      <td>Genetic Algorithms in Search Optimization and ...</td>\n",
       "      <td>1989</td>\n",
       "      <td>16067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4b4279db68b16e20fbc56f9d41980a950191d30a</th>\n",
       "      <td>Adaptation in natural and artificial systems</td>\n",
       "      <td>1975</td>\n",
       "      <td>15985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162d958ff885f1462aeda91cd72582323fd6a1f4</th>\n",
       "      <td>Gradient-based learning applied to document re...</td>\n",
       "      <td>1998</td>\n",
       "      <td>15423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e15cf50aa89fee8535703b9f9512fca5bfc43327</th>\n",
       "      <td>Going deeper with convolutions</td>\n",
       "      <td>2015</td>\n",
       "      <td>13348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4d376d6978dad0374edfa6709c9556b42d3594d3</th>\n",
       "      <td>Batch Normalization: Accelerating Deep Network...</td>\n",
       "      <td>2015</td>\n",
       "      <td>13232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54e325aee6b2d476bbbb88615ac15e251c6e8214</th>\n",
       "      <td>Generative Adversarial Nets</td>\n",
       "      <td>2014</td>\n",
       "      <td>11910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e74f9b7f8eec6ba4704c206b93bc8079af3da4bd</th>\n",
       "      <td>ImageNet Large Scale Visual Recognition Challenge</td>\n",
       "      <td>2015</td>\n",
       "      <td>10959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2c733e34d48784a37d717fe43d9e93277a8c53e</th>\n",
       "      <td>ImageNet: A large-scale hierarchical image dat...</td>\n",
       "      <td>2009</td>\n",
       "      <td>10725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6a17ebeeb80cd696bc83a288f1a77ddfc1467079</th>\n",
       "      <td>System Identification: Theory for the User</td>\n",
       "      <td>1987</td>\n",
       "      <td>9534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5</th>\n",
       "      <td>Neural Machine Translation by Jointly Learning...</td>\n",
       "      <td>2014</td>\n",
       "      <td>9506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111fd833a4ae576cfdbb27d87d2f8fc0640af355</th>\n",
       "      <td>Learning internal representations by error pro...</td>\n",
       "      <td>1986</td>\n",
       "      <td>9234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82266f6103bade9005ec555ed06ba20b5210ff22</th>\n",
       "      <td>Gaussian processes for machine learning</td>\n",
       "      <td>2006</td>\n",
       "      <td>8025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e</th>\n",
       "      <td>Reducing the dimensionality of data with neura...</td>\n",
       "      <td>2006</td>\n",
       "      <td>7590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b07ce649d6f6eb636872527104b0209d3edc8188</th>\n",
       "      <td>Pattern classification and scene analysis</td>\n",
       "      <td>1973</td>\n",
       "      <td>7391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5d90f06bb70a0a3dced62413346235c02b1aa086</th>\n",
       "      <td>Learning Multiple Layers of Features from Tiny...</td>\n",
       "      <td>2009</td>\n",
       "      <td>6938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71b7178df5d2b112d07e45038cb5637208659ff7</th>\n",
       "      <td>Microsoft COCO: Common Objects in Context</td>\n",
       "      <td>2014</td>\n",
       "      <td>6938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d</th>\n",
       "      <td>Human-level control through deep reinforcement...</td>\n",
       "      <td>2015</td>\n",
       "      <td>6647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      title  \\\n",
       "id                                                                                            \n",
       "abd1c342495432171beb7ca8fd9551ef13cbd0ff  ImageNet Classification with Deep Convolutiona...   \n",
       "a6cb366736791bcccc5c8639de5a8f9636bf87e8         Adam: A Method for Stochastic Optimization   \n",
       "2c03df8b48bf3fa39054345bafabfeff15bfd11d       Deep Residual Learning for Image Recognition   \n",
       "eb42cf88027de515750f230b23b1a057dc782108  Very Deep Convolutional Networks for Large-Sca...   \n",
       "13d4c2f76a7c1a4d0a71204e1d5d263a3f5a7986                                     Random Forests   \n",
       "44d2abe2175df8153f465f6c39b68b76a0d40ab9                             Long Short-Term Memory   \n",
       "97efafdb4a3942ab3efba53ded7413199f79c054            Reinforcement Learning: An Introduction   \n",
       "4f607f03272e4d62708f5b2441355f9e005cb452                                Convex Optimization   \n",
       "2e62d1345b340d5fda3b092c460264b9543bc4b5  Genetic Algorithms in Search Optimization and ...   \n",
       "4b4279db68b16e20fbc56f9d41980a950191d30a       Adaptation in natural and artificial systems   \n",
       "162d958ff885f1462aeda91cd72582323fd6a1f4  Gradient-based learning applied to document re...   \n",
       "e15cf50aa89fee8535703b9f9512fca5bfc43327                     Going deeper with convolutions   \n",
       "4d376d6978dad0374edfa6709c9556b42d3594d3  Batch Normalization: Accelerating Deep Network...   \n",
       "54e325aee6b2d476bbbb88615ac15e251c6e8214                        Generative Adversarial Nets   \n",
       "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd  ImageNet Large Scale Visual Recognition Challenge   \n",
       "d2c733e34d48784a37d717fe43d9e93277a8c53e  ImageNet: A large-scale hierarchical image dat...   \n",
       "6a17ebeeb80cd696bc83a288f1a77ddfc1467079         System Identification: Theory for the User   \n",
       "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5  Neural Machine Translation by Jointly Learning...   \n",
       "111fd833a4ae576cfdbb27d87d2f8fc0640af355  Learning internal representations by error pro...   \n",
       "82266f6103bade9005ec555ed06ba20b5210ff22            Gaussian processes for machine learning   \n",
       "46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e  Reducing the dimensionality of data with neura...   \n",
       "b07ce649d6f6eb636872527104b0209d3edc8188          Pattern classification and scene analysis   \n",
       "5d90f06bb70a0a3dced62413346235c02b1aa086  Learning Multiple Layers of Features from Tiny...   \n",
       "71b7178df5d2b112d07e45038cb5637208659ff7          Microsoft COCO: Common Objects in Context   \n",
       "e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d  Human-level control through deep reinforcement...   \n",
       "\n",
       "                                          year  num_citations  \n",
       "id                                                             \n",
       "abd1c342495432171beb7ca8fd9551ef13cbd0ff  2012          40246  \n",
       "a6cb366736791bcccc5c8639de5a8f9636bf87e8  2015          33621  \n",
       "2c03df8b48bf3fa39054345bafabfeff15bfd11d  2016          32655  \n",
       "eb42cf88027de515750f230b23b1a057dc782108  2014          27495  \n",
       "13d4c2f76a7c1a4d0a71204e1d5d263a3f5a7986  2004          24563  \n",
       "44d2abe2175df8153f465f6c39b68b76a0d40ab9  1997          20985  \n",
       "97efafdb4a3942ab3efba53ded7413199f79c054  2005          18170  \n",
       "4f607f03272e4d62708f5b2441355f9e005cb452  2006          16074  \n",
       "2e62d1345b340d5fda3b092c460264b9543bc4b5  1989          16067  \n",
       "4b4279db68b16e20fbc56f9d41980a950191d30a  1975          15985  \n",
       "162d958ff885f1462aeda91cd72582323fd6a1f4  1998          15423  \n",
       "e15cf50aa89fee8535703b9f9512fca5bfc43327  2015          13348  \n",
       "4d376d6978dad0374edfa6709c9556b42d3594d3  2015          13232  \n",
       "54e325aee6b2d476bbbb88615ac15e251c6e8214  2014          11910  \n",
       "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd  2015          10959  \n",
       "d2c733e34d48784a37d717fe43d9e93277a8c53e  2009          10725  \n",
       "6a17ebeeb80cd696bc83a288f1a77ddfc1467079  1987           9534  \n",
       "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5  2014           9506  \n",
       "111fd833a4ae576cfdbb27d87d2f8fc0640af355  1986           9234  \n",
       "82266f6103bade9005ec555ed06ba20b5210ff22  2006           8025  \n",
       "46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e  2006           7590  \n",
       "b07ce649d6f6eb636872527104b0209d3edc8188  1973           7391  \n",
       "5d90f06bb70a0a3dced62413346235c02b1aa086  2009           6938  \n",
       "71b7178df5d2b112d07e45038cb5637208659ff7  2014           6938  \n",
       "e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d  2015           6647  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df.sort_values(\"num_citations\", ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most cited papers within the subgraph\n",
    "\n",
    "The following shows papers that are cited most often **within this subgraph**. These papers tend to be more relevant to the root paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>num_citations</th>\n",
       "      <th>subgraph_citation_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d</th>\n",
       "      <td>Human-level control through deep reinforcement...</td>\n",
       "      <td>2015</td>\n",
       "      <td>6647</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f82e4ff4f003581330338aaae71f60316e58dd26</th>\n",
       "      <td>The Arcade Learning Environment: An Evaluation...</td>\n",
       "      <td>2013</td>\n",
       "      <td>1003</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97efafdb4a3942ab3efba53ded7413199f79c054</th>\n",
       "      <td>Reinforcement Learning: An Introduction</td>\n",
       "      <td>2005</td>\n",
       "      <td>18170</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69e76e16740ed69f4dc55361a3d319ac2f1293dd</th>\n",
       "      <td>Asynchronous Methods for Deep Reinforcement Le...</td>\n",
       "      <td>2016</td>\n",
       "      <td>2365</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e4257bc131c36504a04382290cbc27ca8bb27813</th>\n",
       "      <td>Action-Conditional Video Prediction using Deep...</td>\n",
       "      <td>2015</td>\n",
       "      <td>444</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a6cb366736791bcccc5c8639de5a8f9636bf87e8</th>\n",
       "      <td>Adam: A Method for Stochastic Optimization</td>\n",
       "      <td>2015</td>\n",
       "      <td>33621</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e635d81a617d1239232a9c9a11a196c53dab8240</th>\n",
       "      <td>Bandit Based Monte-Carlo Planning</td>\n",
       "      <td>2006</td>\n",
       "      <td>1593</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6ce57ab17fcd507b856a79874063b59555c76b3a</th>\n",
       "      <td>Learning to Predict by the Methods of Temporal...</td>\n",
       "      <td>2005</td>\n",
       "      <td>2365</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c6170fa90d3b2efede5a2e1660cb23e1c824f2ca</th>\n",
       "      <td>Prioritized Experience Replay</td>\n",
       "      <td>2015</td>\n",
       "      <td>864</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0ab3f7ecbdc5a33565a234215604a6ca9d155a33</th>\n",
       "      <td>Rainbow: Combining Improvements in Deep Reinfo...</td>\n",
       "      <td>2018</td>\n",
       "      <td>397</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60b7d47758a71978e74edff6dd8dea4d9c791d7a</th>\n",
       "      <td>PILCO: A Model-Based and Data-Efficient Approa...</td>\n",
       "      <td>2011</td>\n",
       "      <td>642</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3b9732bb07dc99bde5e1f9f75251c6ea5039373e</th>\n",
       "      <td>Deep Reinforcement Learning with Double Q-Lear...</td>\n",
       "      <td>2016</td>\n",
       "      <td>1388</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846aedd869a00c09b40f1f1f35673cb22bc87490</th>\n",
       "      <td>Mastering the game of Go with deep neural netw...</td>\n",
       "      <td>2016</td>\n",
       "      <td>4912</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d7bd6e3addd8bc8e2e154048300eea15f030ed33</th>\n",
       "      <td>Reinforcement Learning with Unsupervised Auxil...</td>\n",
       "      <td>2017</td>\n",
       "      <td>475</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b5f8a0858fb82ce0e50b55446577a70e40137aaf</th>\n",
       "      <td>Integrated Architectures for Learning, Plannin...</td>\n",
       "      <td>1990</td>\n",
       "      <td>969</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2319a491378867c7049b3da055c5df60e1671158</th>\n",
       "      <td>Playing Atari with Deep Reinforcement Learning</td>\n",
       "      <td>2013</td>\n",
       "      <td>2793</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39b19ea254b0952f2abd23ad899420749816bb1d</th>\n",
       "      <td>The Predictron: End-To-End Learning and Planning</td>\n",
       "      <td>2017</td>\n",
       "      <td>113</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4c05d7caa357148f0bbd61720bdd35f0bc05eb81</th>\n",
       "      <td>Dueling Network Architectures for Deep Reinfor...</td>\n",
       "      <td>2016</td>\n",
       "      <td>838</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d5d64db0dcd088a9db3480aecf52a3f96dc1499b</th>\n",
       "      <td>Efficient Selectivity and Backup Operators in ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>644</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54c4cf3a8168c1b70f91cf78a3dc98b671935492</th>\n",
       "      <td>Reinforcement learning for robots using neural...</td>\n",
       "      <td>1992</td>\n",
       "      <td>529</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      title  \\\n",
       "e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d  Human-level control through deep reinforcement...   \n",
       "f82e4ff4f003581330338aaae71f60316e58dd26  The Arcade Learning Environment: An Evaluation...   \n",
       "97efafdb4a3942ab3efba53ded7413199f79c054            Reinforcement Learning: An Introduction   \n",
       "69e76e16740ed69f4dc55361a3d319ac2f1293dd  Asynchronous Methods for Deep Reinforcement Le...   \n",
       "e4257bc131c36504a04382290cbc27ca8bb27813  Action-Conditional Video Prediction using Deep...   \n",
       "a6cb366736791bcccc5c8639de5a8f9636bf87e8         Adam: A Method for Stochastic Optimization   \n",
       "e635d81a617d1239232a9c9a11a196c53dab8240                  Bandit Based Monte-Carlo Planning   \n",
       "6ce57ab17fcd507b856a79874063b59555c76b3a  Learning to Predict by the Methods of Temporal...   \n",
       "c6170fa90d3b2efede5a2e1660cb23e1c824f2ca                      Prioritized Experience Replay   \n",
       "0ab3f7ecbdc5a33565a234215604a6ca9d155a33  Rainbow: Combining Improvements in Deep Reinfo...   \n",
       "60b7d47758a71978e74edff6dd8dea4d9c791d7a  PILCO: A Model-Based and Data-Efficient Approa...   \n",
       "3b9732bb07dc99bde5e1f9f75251c6ea5039373e  Deep Reinforcement Learning with Double Q-Lear...   \n",
       "846aedd869a00c09b40f1f1f35673cb22bc87490  Mastering the game of Go with deep neural netw...   \n",
       "d7bd6e3addd8bc8e2e154048300eea15f030ed33  Reinforcement Learning with Unsupervised Auxil...   \n",
       "b5f8a0858fb82ce0e50b55446577a70e40137aaf  Integrated Architectures for Learning, Plannin...   \n",
       "2319a491378867c7049b3da055c5df60e1671158     Playing Atari with Deep Reinforcement Learning   \n",
       "39b19ea254b0952f2abd23ad899420749816bb1d   The Predictron: End-To-End Learning and Planning   \n",
       "4c05d7caa357148f0bbd61720bdd35f0bc05eb81  Dueling Network Architectures for Deep Reinfor...   \n",
       "d5d64db0dcd088a9db3480aecf52a3f96dc1499b  Efficient Selectivity and Backup Operators in ...   \n",
       "54c4cf3a8168c1b70f91cf78a3dc98b671935492  Reinforcement learning for robots using neural...   \n",
       "\n",
       "                                          year  num_citations  \\\n",
       "e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d  2015           6647   \n",
       "f82e4ff4f003581330338aaae71f60316e58dd26  2013           1003   \n",
       "97efafdb4a3942ab3efba53ded7413199f79c054  2005          18170   \n",
       "69e76e16740ed69f4dc55361a3d319ac2f1293dd  2016           2365   \n",
       "e4257bc131c36504a04382290cbc27ca8bb27813  2015            444   \n",
       "a6cb366736791bcccc5c8639de5a8f9636bf87e8  2015          33621   \n",
       "e635d81a617d1239232a9c9a11a196c53dab8240  2006           1593   \n",
       "6ce57ab17fcd507b856a79874063b59555c76b3a  2005           2365   \n",
       "c6170fa90d3b2efede5a2e1660cb23e1c824f2ca  2015            864   \n",
       "0ab3f7ecbdc5a33565a234215604a6ca9d155a33  2018            397   \n",
       "60b7d47758a71978e74edff6dd8dea4d9c791d7a  2011            642   \n",
       "3b9732bb07dc99bde5e1f9f75251c6ea5039373e  2016           1388   \n",
       "846aedd869a00c09b40f1f1f35673cb22bc87490  2016           4912   \n",
       "d7bd6e3addd8bc8e2e154048300eea15f030ed33  2017            475   \n",
       "b5f8a0858fb82ce0e50b55446577a70e40137aaf  1990            969   \n",
       "2319a491378867c7049b3da055c5df60e1671158  2013           2793   \n",
       "39b19ea254b0952f2abd23ad899420749816bb1d  2017            113   \n",
       "4c05d7caa357148f0bbd61720bdd35f0bc05eb81  2016            838   \n",
       "d5d64db0dcd088a9db3480aecf52a3f96dc1499b  2006            644   \n",
       "54c4cf3a8168c1b70f91cf78a3dc98b671935492  1992            529   \n",
       "\n",
       "                                          subgraph_citation_count  \n",
       "e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d                       18  \n",
       "f82e4ff4f003581330338aaae71f60316e58dd26                       15  \n",
       "97efafdb4a3942ab3efba53ded7413199f79c054                       14  \n",
       "69e76e16740ed69f4dc55361a3d319ac2f1293dd                       14  \n",
       "e4257bc131c36504a04382290cbc27ca8bb27813                        9  \n",
       "a6cb366736791bcccc5c8639de5a8f9636bf87e8                        8  \n",
       "e635d81a617d1239232a9c9a11a196c53dab8240                        8  \n",
       "6ce57ab17fcd507b856a79874063b59555c76b3a                        8  \n",
       "c6170fa90d3b2efede5a2e1660cb23e1c824f2ca                        8  \n",
       "0ab3f7ecbdc5a33565a234215604a6ca9d155a33                        8  \n",
       "60b7d47758a71978e74edff6dd8dea4d9c791d7a                        8  \n",
       "3b9732bb07dc99bde5e1f9f75251c6ea5039373e                        8  \n",
       "846aedd869a00c09b40f1f1f35673cb22bc87490                        8  \n",
       "d7bd6e3addd8bc8e2e154048300eea15f030ed33                        7  \n",
       "b5f8a0858fb82ce0e50b55446577a70e40137aaf                        7  \n",
       "2319a491378867c7049b3da055c5df60e1671158                        7  \n",
       "39b19ea254b0952f2abd23ad899420749816bb1d                        7  \n",
       "4c05d7caa357148f0bbd61720bdd35f0bc05eb81                        7  \n",
       "d5d64db0dcd088a9db3480aecf52a3f96dc1499b                        6  \n",
       "54c4cf3a8168c1b70f91cf78a3dc98b671935492                        6  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c = Counter()\n",
    "process_recursively(root, lambda p: c.update([p[\"id\"]]))\n",
    "paper_counts_df = pd.DataFrame.from_records(c.most_common(), columns=[\"id\", \"subgraph_citation_count\"], index=\"id\")\n",
    "paper_counts_df = pd.concat([papers_df, paper_counts_df], axis=1)\n",
    "paper_counts_df.sort_values(\"subgraph_citation_count\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
